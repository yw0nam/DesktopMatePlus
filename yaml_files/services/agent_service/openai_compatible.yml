# Agent Service Configuration
llm_config:
  type: "openai_compatible"  # Service type for factory
  configs:
    openai_api_base: "http://localhost:55120/v1"
    model: "chat_model"
    # openai_api_key is loaded from LLM_API_KEY environment variable
    temperature: 0.7
    top_p: 0.9

memory_config:
  type: "mem0"  # Memory provider type
  configs:
    # Memory configurations will be added here
