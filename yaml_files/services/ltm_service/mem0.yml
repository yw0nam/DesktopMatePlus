# LTM Service Configuration for Mem0
# API credentials are loaded from environment variables (.env file):

ltm_config:
  type: "mem0"  # Service type for factory
  configs:
    llm:
      provider: "openai"
      config:
        openai_base_url: "http://localhost:55120/v1"
        model: "chat_model"
        # api_key: "${LTM_API_KEY}"
    embedder:
      provider: "langchain" # Currently only langchain is supported. This is compatible with OpenAI compatible embeddings API.
      config:
        openai_base_url: "http://localhost:5504/v1"
        model_name: "chat_model"
        embedding_dims: 2560
        # openai_api_key: "${EMB_API_KEY}"
    vector_store:
      provider: "qdrant"
      config:
        url: "localhost"
        embedding_model_dims: 2560
        collection_name: "ltm_collection"
    graph_store:
      provider: "neo4j"
      config:
        url: "bolt://localhost:7687"
        # username: ${NEO4J_USER}
        # password: ${NEO4J_PASSWORD}
