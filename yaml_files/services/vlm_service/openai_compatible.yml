# OpenAI Compatible VLM Service Configuration
# API credentials are loaded from environment variables (.env file):

vlm_config:
  type: "openai_compatible"  # Service type for factory
  configs:
    temperature: 0.7
    top_p: 0.9
    model_name: "chat_model"
    openai_api_base: "http://localhost:5530/v1"
    # openai_api_key: "token-abc123"  # Loaded from VLM_API_KEY environment variable
